{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"homework.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6-final"}},"cells":[{"cell_type":"markdown","metadata":{"id":"l3-TPnUAiwPn"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"hCly--9oiwPq","executionInfo":{"status":"ok","timestamp":1607615572800,"user_tz":-60,"elapsed":2284,"user":{"displayName":"Massimiliano Roccamena","photoUrl":"","userId":"12236198619343584688"}}},"source":["import os\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","SEED = 1234\n","tf.random.set_seed(SEED)\n","np.random.seed(SEED)\n","\n","cwd = os.getcwd()\n","drive_path = os.path.join(cwd, 'drive')\n","my_drive_path = os.path.join(drive_path, 'My Drive')\n","\n","project_path = os.path.join(my_drive_path, 'AN2DL-Project')\n","data_path = os.path.join(project_path, 'data')\n","train_path = os.path.join(data_path, 'Training')\n","test_path = os.path.join(data_path, 'Test_Dev')\n","logs_path = os.path.join(project_path, 'logs')\n","results_path = os.path.join(project_path, 'results')\n","\n","X_dir = 'Images'\n","Y_dir = 'Masks'\n","\n","teams = ['Bipbip','Pead','Roseau','Weedelec']\n","crops = ['Haricot','Mais']\n","\n","train_imgs_path = os.path.join(train_path, 'training.txt')\n","valid_imgs_path = os.path.join(train_path, 'validation.txt')"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ecviux3AkrC1","executionInfo":{"status":"ok","timestamp":1607615606180,"user_tz":-60,"elapsed":31587,"user":{"displayName":"Massimiliano Roccamena","photoUrl":"","userId":"12236198619343584688"}},"outputId":"20d2ff5b-a301-48f1-96fb-2caa55b3c565"},"source":["from google.colab import drive\n","drive.mount(drive_path)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82CeVOq5ZGRg","executionInfo":{"status":"ok","timestamp":1607615615793,"user_tz":-60,"elapsed":6631,"user":{"displayName":"Massimiliano Roccamena","photoUrl":"","userId":"12236198619343584688"}},"outputId":"ca7e8471-d78c-441f-a0f5-de425fe108ee"},"source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oCXYwkJaiwPw"},"source":["## Preprocessing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5OLvO6rrsg7x","executionInfo":{"elapsed":956,"status":"ok","timestamp":1607596864929,"user":{"displayName":"Massimiliano Roccamena","photoUrl":"","userId":"12236198619343584688"},"user_tz":-60},"outputId":"953319c8-3d04-45db-bba7-b3f2826f8402"},"source":["# Splitting all data in train/valid on random teams and crops\r\n","\r\n","train_imgs_stream = open(train_imgs_path, 'w')\r\n","valid_imgs_stream = open(valid_imgs_path, 'w')\r\n","\r\n","for team in teams:\r\n","  for crop in crops:\r\n","    curr_imgs = []\r\n","\r\n","    for root,dirs,files in os.walk(os.path.join(train_path, team, crop, X_dir)):\r\n","      print(\"Found {} images for team {}, crop {}\".format(len(files),team,crop))\r\n","      for file in files:\r\n","        curr_imgs.append(os.path.splitext(file)[0])\r\n","\r\n","    np.random.shuffle(curr_imgs)\r\n","    curr_valid = curr_imgs[:18]\r\n","    curr_train = curr_imgs[18:]\r\n","\r\n","    for t in curr_train:\r\n","      train_imgs_stream.write(\"{} {} {}\\n\".format(team, crop, t))\r\n","    for v in curr_valid:\r\n","      valid_imgs_stream.write(\"{} {} {}\\n\".format(team, crop, v))\r\n","\r\n","train_imgs_stream.close()\r\n","valid_imgs_stream.close()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 90 images for team Bipbip, crop Haricot\n","Found 90 images for team Bipbip, crop Mais\n","Found 90 images for team Pead, crop Haricot\n","Found 90 images for team Pead, crop Mais\n","Found 90 images for team Roseau, crop Haricot\n","Found 90 images for team Roseau, crop Mais\n","Found 90 images for team Weedelec, crop Haricot\n","Found 90 images for team Weedelec, crop Mais\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yRE0thJcrgxD","executionInfo":{"status":"ok","timestamp":1607616916422,"user_tz":-60,"elapsed":1145,"user":{"displayName":"Massimiliano Roccamena","photoUrl":"","userId":"12236198619343584688"}}},"source":["img_h = 256\r\n","img_w = 256\r\n","\r\n","num_channels = 3\r\n","num_classes = 4\r\n","\r\n","batch_size = 4\r\n","\r\n","classes_colors = ([216, 124, 18],\r\n","                [255, 255, 255],\r\n","                [216, 67, 82])\r\n","\r\n","def rgb_to_target_mask(mask_rgb):\r\n","    mask_arr = np.array(mask_rgb)\r\n","\r\n","    new_mask_arr = np.zeros(mask_arr.shape[:2], dtype=mask_arr.dtype)\r\n","\r\n","    new_mask_arr[np.where(np.all(mask_arr == [216, 124, 18], axis=-1))] = 0\r\n","    new_mask_arr[np.where(np.all(mask_arr == [255, 255, 255], axis=-1))] = 1\r\n","    new_mask_arr[np.where(np.all(mask_arr == [216, 67, 82], axis=-1))] = 2\r\n","\r\n","    return new_mask_arr\r\n","\r\n","def target_to_rgb_mask(mask_arr):\r\n","    mask_arr = np.array(mask_arr)\r\n","\r\n","    new_mask_rgb = np.zeros(mask_arr.shape[:2], dtype=mask_arr.dtype)\r\n","\r\n","    new_mask_rgb[np.where(np.all(mask_arr == 0, axis=-1))] = [216, 124, 18]\r\n","    new_mask_rgb[np.where(np.all(mask_arr == 1, axis=-1))] = [255, 255, 255]\r\n","    new_mask_rgb[np.where(np.all(mask_arr == 2, axis=-1))] = [216, 67, 82]\r\n","\r\n","    return new_mask_rgb"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"C4chsdJNiwPx","executionInfo":{"status":"ok","timestamp":1607616921095,"user_tz":-60,"elapsed":824,"user":{"displayName":"Massimiliano Roccamena","photoUrl":"","userId":"12236198619343584688"}}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","img_data_gen = ImageDataGenerator(rotation_range=10,\n","                                      width_shift_range=3,\n","                                      height_shift_range=3,\n","                                      zoom_range=0.3,\n","                                      horizontal_flip=True,\n","                                      vertical_flip=True,\n","                                      fill_mode='reflect')\n","mask_data_gen = ImageDataGenerator(rotation_range=10,\n","                                      width_shift_range=3,\n","                                      height_shift_range=3,\n","                                      zoom_range=0.3,\n","                                      horizontal_flip=True,\n","                                      vertical_flip=True,\n","                                      fill_mode='reflect')"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"21oRTe-EP_0E","executionInfo":{"status":"ok","timestamp":1607617571844,"user_tz":-60,"elapsed":944,"user":{"displayName":"Massimiliano Roccamena","photoUrl":"","userId":"12236198619343584688"}}},"source":["from PIL import Image\r\n","\r\n","class CustomDataset(tf.keras.utils.Sequence):\r\n","  def __init__(self, out_shape, which_subset, img_generator=None, mask_generator=None, \r\n","               preprocessing_function=None):\r\n","    self.out_shape = out_shape\r\n","\r\n","    if which_subset == 'training':\r\n","      subset_file = train_imgs_path\r\n","    elif which_subset == 'validation':\r\n","      subset_file = valid_imgs_path\r\n","    \r\n","    with open(subset_file, 'r') as f:\r\n","      subset_data = f.readlines()\r\n","\r\n","    self.which_subset = which_subset\r\n","    self.subset_data = subset_data\r\n","    self.img_generator = img_generator\r\n","    self.mask_generator = mask_generator\r\n","    self.preprocessing_function = preprocessing_function\r\n","\r\n","  def __len__(self):\r\n","    return len(self.subset_data)\r\n","\r\n","  def __getitem__(self, index):\r\n","    team, crop, name = self.subset_data[index].split()\r\n","    img = Image.open(os.path.join(train_path, team, crop, X_dir, name + '.jpg'))\r\n","    mask = Image.open(os.path.join(train_path, team, crop, Y_dir, name + '.png'))\r\n","\r\n","    img = img.resize(self.out_shape)\r\n","    mask = mask.resize(self.out_shape, resample=Image.NEAREST)\r\n","    \r\n","    img_arr = np.array(img)\r\n","    mask_arr = np.array(mask)\r\n","\r\n","    #mask_arr = np.expand_dims(mask_arr, -1)\r\n","    out_mask = mask_arr\r\n","\r\n","    if self.which_subset == 'training':\r\n","      if self.img_generator is not None and self.mask_generator is not None:\r\n","        img_t = self.img_generator.get_random_transform(img_arr.shape, seed=SEED)\r\n","        mask_t = self.mask_generator.get_random_transform(mask_arr.shape, seed=SEED)\r\n","        img_arr = self.img_generator.apply_transform(img_arr, img_t)\r\n","        out_mask = np.zeros_like(mask_arr)\r\n","        #np.unique(mask_arr)\r\n","        for c in classes_colors:\r\n","          #if c > 0:\r\n","          curr_class_arr = np.float32(mask_arr == c)\r\n","          curr_class_arr = self.mask_generator.apply_transform(curr_class_arr, mask_t)\r\n","          curr_class_arr = np.uint8(curr_class_arr)\r\n","          curr_class_arr = curr_class_arr * c \r\n","          out_mask = out_mask + curr_class_arr\r\n","    \r\n","    if self.preprocessing_function is not None:\r\n","      img_arr = self.preprocessing_function(img_arr)\r\n","\r\n","    return img_arr, np.float32(out_mask)"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"-kp5dWJciwP6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607617577640,"user_tz":-60,"elapsed":830,"user":{"displayName":"Massimiliano Roccamena","photoUrl":"","userId":"12236198619343584688"}},"outputId":"e1975deb-0fda-4c80-8d10-034256ebd777"},"source":["from tensorflow.keras.applications.vgg16 import preprocess_input \n","\n","train_dataset = CustomDataset((img_h,img_w), 'training', \n","                        img_generator=img_data_gen, mask_generator=mask_data_gen,\n","                        preprocessing_function=preprocess_input)\n","valid_dataset = CustomDataset((img_h,img_w), 'validation', \n","                              preprocessing_function=preprocess_input)\n","\n","print(\"Found {} images for training\".format(len(train_dataset)))\n","print(\"Found {} images for validation\".format(len(valid_dataset)))"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Found 576 images for training\n","Found 144 images for validation\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nzMDazcziwP-","executionInfo":{"status":"ok","timestamp":1607617586238,"user_tz":-60,"elapsed":948,"user":{"displayName":"Massimiliano Roccamena","photoUrl":"","userId":"12236198619343584688"}},"outputId":"d16b0f7a-c7fe-4d84-fcbf-3bc2fa2610c9"},"source":["train_dataset = tf.data.Dataset.from_generator(lambda: train_dataset,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([img_h, img_w, num_channels],\n","                                                              [img_h, img_w, 1]))\n","train_dataset = train_dataset.batch(batch_size)\n","train_dataset = train_dataset.repeat()\n","\n","valid_dataset = tf.data.Dataset.from_generator(lambda: valid_dataset,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([img_h, img_w, num_channels],\n","                                                              [img_h, img_w, 1]))\n","valid_dataset = valid_dataset.batch(batch_size)\n","valid_dataset = valid_dataset.repeat()\n","\n","print(train_dataset)\n","print(valid_dataset)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["<RepeatDataset shapes: ((None, 256, 256, 3), (None, 256, 256, 1)), types: (tf.float32, tf.float32)>\n","<RepeatDataset shapes: ((None, 256, 256, 3), (None, 256, 256, 1)), types: (tf.float32, tf.float32)>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vPwj8MN2O05i"},"source":["iterator = iter(valid_dataset)\r\n","img, target = next(iterator)\r\n","#print(img)\r\n","#print(target)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ALr-dFyeiwQD"},"source":["from matplotlib import cm\n","\n","colors = [cm.rainbow(x) for x in np.linspace(0, 1, 4)]\n","iterator = iter(train_dataset)\n","\n","fig, ax = plt.subplots(1, 2)\n","\n","img, target = next(iterator)\n","img = img[0]\n","img = img\n","\n","target = np.array(target[0, ..., 0])\n","print(np.unique(target))\n","\n","target_img = np.zeros([target.shape[0], target.shape[1], 3])\n","\n","target_img[np.where(target == 0)] = [0, 0, 0]\n","for i in range(1, 5):\n","  target_img[np.where(target == i)] = np.array(colors[i-1])[:3] * 255\n","\n","ax[0].imshow(np.uint8(img))\n","ax[0].set_title(\"Image\")\n","ax[1].imshow(np.uint8(target_img))\n","ax[1].set_title(\"Mask\")\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rYKmHqmLiwQJ"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"tvVvekVR1coC"},"source":["# Encoder\n","\n","finetuning=True\n","freeze_until=15\n","\n","basic_model = tf.keras.applications.VGG16(weights='imagenet',\n","                                          include_top=False, \n","                                          input_shape=(img_h, img_w, num_channels))\n","\n","if finetuning:\n","  for layer in basic_model.layers[:freeze_until]:\n","    layer.trainable = False\n","else:\n","  basic_model.trainable = False\n","\n","#basic_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HhdpP_-GiwQK"},"source":["model = tf.keras.Sequential()\n","model.add(basic_model)\n","\n","# Decoder\n","\n","for i in range(depth):\n","  model.add(tf.keras.layers.UpSampling2D(2, interpolation='bilinear'))\n","  model.add(tf.keras.layers.Conv2D(filters=start_f,\n","                                    kernel_size=(3, 3),\n","                                    strides=(1, 1),\n","                                    padding='same'))\n","  model.add(tf.keras.layers.ReLU())\n","  start_f = start_f // 2\n","\n","model.add(tf.keras.layers.Conv2D(filters=num_classes,\n","                                  kernel_size=(1, 1),\n","                                  strides=(1, 1),\n","                                  padding='same',\n","                                  activation='softmax'))\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dE96xa18iwQQ"},"source":["## Learning"]},{"cell_type":"code","metadata":{"id":"fHIIDPKfZNQv"},"source":["%load_ext tensorboard\n","%tensorboard --logdir /content/drive/MyDrive/AN2DL-Project/logs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OFqAfQMCiwQR"},"source":["loss = tf.keras.losses.CategoricalCrossentropy()\n","lr = 1e-4\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","\n","def meanIoU(y_true, y_pred):\n","    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\n","    per_class_iou = []\n","\n","    for i in range(2,4): # exclude the background class 0\n","      class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\n","      class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\n","      intersection = tf.reduce_sum(class_true * class_pred)\n","      union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\n","      iou = (intersection + 1e-7) / (union + 1e-7)\n","      per_class_iou.append(iou)\n","      \n","    return tf.reduce_mean(per_class_iou)\n","\n","metrics = ['accuracy', meanIoU]\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZNuf-fp2O5s0"},"source":["from datetime import datetime\n","\n","model_name = 'Solution_V1.0'\n","now = datetime.now().strftime('%b%d_%H-%M-%S')\n","exp_dir = os.path.join(logs_path, model_name + '_' + str(now))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ZP8lesWiwQV"},"source":["import os\n","    \n","callbacks = []\n","\n","ckpt_dir = os.path.join(exp_dir, 'ckpts')\n","if not os.path.exists(ckpt_dir):\n","    os.makedirs(ckpt_dir)\n","\n","ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, \n","                                                                        'cp_{epoch:02d}.ckpt'),           \n","                                                    save_weights_only=True,\n","                                                    save_best_only=True)\n","callbacks.append(ckpt_callback)\n","\n","tb_dir = os.path.join(exp_dir, 'tb_logs')\n","if not os.path.exists(tb_dir):\n","    os.makedirs(tb_dir)\n","    \n","tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n","                                             profile_batch=0,\n","                                             histogram_freq=1)\n","callbacks.append(tb_callback)\n","\n","early_stop = True\n","if early_stop:\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)\n","    callbacks.append(es_callback)\n","\n","model.fit(x=train_dataset,\n","          epochs=100,\n","          steps_per_epoch=len(train_gen),\n","          validation_data=valid_dataset,\n","          validation_steps=len(valid_gen), \n","          callbacks=callbacks)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vq4K_u5Ctlet"},"source":["## Test predictions"]},{"cell_type":"code","metadata":{"id":"sNxPGbLT2-3s"},"source":["ckpt_file = input('Enter checkpoint file name: ')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6f4bhrtptx5J"},"source":["from PIL import Image\n","\n","model_path = os.path.join(ckpt_dir, ckpt_file)\n","model.load_weights(model_path)\n","\n","image_filenames = next(os.walk(test_path))[2]\n","\n","results = {}\n","for image_name in image_filenames:\n","    img = Image.open(test_path + '/' + image_name).convert('RGB')\n","    img = img.resize((img_w, img_h))\n","    img_array = np.array(img)\n","    img_array = np.expand_dims(img_array, 0)\n","    img_array = img_array * 1./255\n","    prediction = model.predict(img_array, batch_size=1)\n","    c = np.argmax(prediction)\n","    results[image_name] = c\n","\n","csv_fname = model_name\n","csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n","\n","with open(os.path.join(results_path, csv_fname), 'w') as f:\n","  f.write('Id,Category\\n')\n","\n","  for key, value in results.items():\n","    f.write(key + ',' + str(value) + '\\n')\n","\n","print('Saved {}'.format(csv_fname))"],"execution_count":null,"outputs":[]}]}