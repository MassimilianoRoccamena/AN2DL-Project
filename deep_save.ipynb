{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "deep_save1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3-TPnUAiwPn"
      },
      "source": [
        "## Basic setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCly--9oiwPq"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "SEED = 1234\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "cwd = os.getcwd()\n",
        "drive_path = os.path.join(cwd, 'drive')\n",
        "my_drive_path = os.path.join(drive_path, 'My Drive')\n",
        "\n",
        "project_path = os.path.join(my_drive_path, 'AN2DL-Project')\n",
        "data_path = os.path.join(project_path, 'data')\n",
        "train_path = os.path.join(data_path, 'training')\n",
        "test_path = os.path.join(data_path, 'test')\n",
        "logs_path = os.path.join(project_path, 'logs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecviux3AkrC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69bf51c4-62fc-4cc4-bb69-d8e2fe559b67"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(drive_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCXYwkJaiwPw"
      },
      "source": [
        "## Images and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4chsdJNiwPx"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "apply_data_augmentation = True\n",
        "validation_split = 0.175\n",
        "\n",
        "if apply_data_augmentation:\n",
        "    train_data_gen = ImageDataGenerator(rotation_range=10,\n",
        "                                        width_shift_range=1.5,\n",
        "                                        height_shift_range=1.5,\n",
        "                                        zoom_range=0.2,\n",
        "                                        horizontal_flip=True,\n",
        "                                        fill_mode='constant',\n",
        "                                        cval=0,\n",
        "                                        rescale=1./255,\n",
        "                                        validation_split=validation_split)\n",
        "else:\n",
        "    train_data_gen = ImageDataGenerator(rescale=1./255,\n",
        "                                        validation_split=validation_split)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C33mP_eiwP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a070ca7e-633c-4576-95fd-a324738a8f0e"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "labels_df = pd.read_json(os.path.join(data_path,'train_gt.json'), orient='index')\n",
        "labels_df = pd.DataFrame([(x,str(y)) for x,y in zip(labels_df.index, labels_df[0])])\n",
        "labels_df.rename(columns={0:'file',1:'class'}, inplace=True)\n",
        "print(labels_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8rj2C4MiwP5"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kp5dWJciwP6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1052c28f-58ff-4fce-df6e-6b236904f9cd"
      },
      "source": [
        "img_h = 299\n",
        "img_w = 299\n",
        "bs = 8\n",
        "\n",
        "train_gen = train_data_gen.flow_from_dataframe(dataframe=labels_df,\n",
        "                                            target_size=(img_h,img_w),\n",
        "                                            directory=train_path,\n",
        "                                            x_col='file',\n",
        "                                            y_col='class',\n",
        "                                            batch_size=bs, \n",
        "                                            class_mode='categorical',\n",
        "                                            shuffle=True,\n",
        "                                            seed=SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzMDazcziwP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ff9b59-33cc-4aa3-da2f-2fa1bc2fb7ce"
      },
      "source": [
        "num_channels = 3\n",
        "num_classes = 3\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([None, img_h, img_w, num_channels],\n",
        "                                               [None, num_classes]))\n",
        "train_dataset = train_dataset.repeat()\n",
        "\n",
        "print(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYKmHqmLiwQJ"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhdpP_-GiwQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27cfa7c8-5ec9-47fb-9fc5-a734a9c61641"
      },
      "source": [
        "basic_model = tf.keras.applications.InceptionResNetV2(pooling='avg',\n",
        "                                                      weights='imagenet',\n",
        "                                                      include_top=False, \n",
        "                                                      input_shape=(img_h, img_w, num_channels))\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(basic_model)\n",
        "model.add(tf.keras.layers.Dropout(0.6))\n",
        "model.add(tf.keras.layers.Dense(1500, activation='linear'))\n",
        "model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knEz9zUQVkHa"
      },
      "source": [
        "model_path = os.path.join(logs_path, 'Trial/ckpts/cp_06.ckpt')\n",
        "model.load_weights(model_path)\n",
        "\n",
        "encoding_size = 1536"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuQNMRTyXsms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff41ba01-d502-4c1d-b74c-c51bd8729ce1"
      },
      "source": [
        "encoder = tf.keras.Sequential()\n",
        "encoder.add(model.layers[0])\n",
        "del model\n",
        "\n",
        "encoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTeISTIhXQJq"
      },
      "source": [
        "# Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxalH90HZWWt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5743526-fd8c-4de0-d6f4-17d7dc14f42b"
      },
      "source": [
        "dataset_size = 5606\n",
        "\n",
        "iterator = iter(train_dataset)\n",
        "\n",
        "file_name = 'training_deep_new.csv'\n",
        "output_path = os.path.join(data_path, file_name)\n",
        "\n",
        "with open(output_path, 'w') as f:\n",
        "  for i in range(encoding_size):\n",
        "    f.write('C{},'.format(i+1))\n",
        "  f.write('Class\\n')\n",
        "\n",
        "  batch_count = int(dataset_size/bs)\n",
        "  progress_bins = 20\n",
        "  progress_period = int(batch_count/progress_bins)\n",
        "\n",
        "  for i in range(batch_count):\n",
        "    imgs, targets = next(iterator)\n",
        "    img_encoded = encoder.predict(imgs)\n",
        "\n",
        "    curr_bs = imgs.shape[0]\n",
        "    for j in range(curr_bs):\n",
        "      curr_encoded = img_encoded[j]\n",
        "\n",
        "      for k in range(encoding_size):\n",
        "        f.write('{},'.format(curr_encoded[k]))\n",
        "      \n",
        "      curr_target = targets[j]\n",
        "      curr_target = np.argmax(curr_target)\n",
        "      f.write('{}\\n'.format(curr_target))\n",
        "\n",
        "    if i%progress_period == progress_period-1:\n",
        "      print('Completed {:.1f}%'.format(i/progress_period/progress_bins*100))\n",
        "\n",
        "print('Saved {}'.format(file_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAX2BVhoaSpS"
      },
      "source": [
        "# Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvWdzpnTaVF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b414db-c4ad-4d86-d5c7-d77eb58ede1a"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "image_filenames = next(os.walk(test_path))[2]\n",
        "\n",
        "file_name = 'test_deep_new.csv'\n",
        "output_path = os.path.join(data_path, file_name)\n",
        "\n",
        "with open(output_path, 'w') as f:\n",
        "  f.write('Id,')\n",
        "  for i in range(encoding_size-1):\n",
        "    f.write('C{},'.format(i+1))\n",
        "  f.write('C{}\\n'.format(encoding_size))\n",
        "\n",
        "  progress_bins = 20\n",
        "  progress_period = int(len(image_filenames)/progress_bins)\n",
        "  \n",
        "  for i,image_name in enumerate(image_filenames):\n",
        "      img = Image.open(test_path + '/' + image_name).convert('RGB')\n",
        "      img = img.resize((img_w, img_h))\n",
        "      img_array = np.array(img)\n",
        "      img_array = np.expand_dims(img_array, 0)\n",
        "      img_array = img_array * 1./255\n",
        "      img_encoded = encoder.predict(img_array, batch_size=1)[0]\n",
        "\n",
        "      f.write('{},'.format(image_name))\n",
        "      for i in img_encoded[:-1]:\n",
        "        f.write('{},'.format(i))\n",
        "      f.write('{}\\n'.format(img_encoded[-1]))\n",
        "\n",
        "      if i%progress_period == progress_period-1:\n",
        "        print('Completed {:.1f}%'.format(i/progress_period/progress_bins*100))\n",
        "\n",
        "  print('Saved {}'.format(file_name))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}